{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10201347,"sourceType":"datasetVersion","datasetId":6192936}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artificial Neural Networks and Deep Learning\n\n---\n\n## SiumGPT Homework 2 Final Notebook (Models Ensemble)","metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Import Libraries","metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":"# Set seed for reproducibility\nseed = 42\n\n# Import necessary libraries\nimport os\n\n# Set environment variables before importing modules\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Import necessary modules\nimport logging\nimport random\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n# Set seeds for random number generators in NumPy and Python\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Import TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\n\n# Set seed for TensorFlow\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\n\n# Reduce TensorFlow verbosity\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n# Enable check for NaNs and Infs\n#tf.debugging.enable_check_numerics()\n# Log device placement information\n#tf.debugging.set_log_device_placement(True)\n# Disable traceback filtering to see the full traceback\n#tf.config.experimental_run_functions_eagerly(True)\n\n# Print TensorFlow version\nprint(tf.__version__)\n\n# Import other libraries\nimport albumentations as A\nimport os\nimport math\nfrom PIL import Image\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.keras.backend as K\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom keras.utils import to_categorical\nfrom keras.saving import load_model\nfrom keras.metrics import MeanIoU\nfrom keras import saving as ks\n\n# Configure plot display settings\nsns.set(font_scale=1.4)\nsns.set_style('white')\nplt.rc('font', size=14)\n%matplotlib inline\n\n!pip install -U segmentation-models\nimport segmentation_models as sm\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\nprint(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"id":"CO6_Ft_8T56A","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:41:42.001476Z","iopub.execute_input":"2024-12-14T18:41:42.001935Z","iopub.status.idle":"2024-12-14T18:42:05.836347Z","shell.execute_reply.started":"2024-12-14T18:41:42.001906Z","shell.execute_reply":"2024-12-14T18:42:05.835317Z"}},"outputs":[{"name":"stdout","text":"2.16.1\nCollecting segmentation-models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl.metadata (938 bytes)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from segmentation-models)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\nCollecting image-classifiers==1.0.0 (from segmentation-models)\n  Downloading image_classifiers-1.0.0-py3-none-any.whl.metadata (8.6 kB)\nCollecting efficientnet==1.0.0 (from segmentation-models)\n  Downloading efficientnet-1.0.0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.0.0->segmentation-models) (0.23.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.26.4)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.11.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.14.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.2)\nDownloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nDownloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nDownloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nDownloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\nSegmentation Models: using `tf.keras` framework.\nTensorFlow version: 2.16.1\nKeras version: 3.3.3\nGPU devices: 1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## ‚è≥ Load the Data","metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/mars_for_students.npz\")\n\ntraining_set = data[\"training_set\"]\nX_train = training_set[:, 0]\ny_train = training_set[:, 1]\n\nX_test = data[\"test_set\"]\n\n# not used, just as a reference\nlabels = {\n    0: \"Background\",\n    1: \"Soil\",\n    2: \"Bedrock\",\n    3: \"Sand\",\n    4: \"Big Rock\"\n}\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","metadata":{"id":"pLaoDaG1V1Yg","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:05.838144Z","iopub.execute_input":"2024-12-14T18:42:05.838959Z","iopub.status.idle":"2024-12-14T18:42:08.263814Z","shell.execute_reply.started":"2024-12-14T18:42:05.838927Z","shell.execute_reply":"2024-12-14T18:42:08.262965Z"}},"outputs":[{"name":"stdout","text":"Training X shape: (2615, 64, 128)\nTraining y shape: (2615, 64, 128)\nTest X shape: (10022, 64, 128)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Removing aliens\nalien_label = y_train[1834, :]\n#plt.imshow(alien_label, cmap='viridis')\n\nfilter = [True] * X_train.shape[0]\nremoved = 0\nfor i, lab in enumerate(y_train):\n    if np.array_equal(alien_label, lab):\n        filter[i] = False\n        removed += 1\n\nX_train = X_train[filter]\ny_train = y_train[filter]\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")\nprint(f'Removed {removed} images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:08.264959Z","iopub.execute_input":"2024-12-14T18:42:08.265264Z","iopub.status.idle":"2024-12-14T18:42:08.393008Z","shell.execute_reply.started":"2024-12-14T18:42:08.265236Z","shell.execute_reply":"2024-12-14T18:42:08.392041Z"}},"outputs":[{"name":"stdout","text":"Training X shape: (2505, 64, 128)\nTraining y shape: (2505, 64, 128)\nRemoved 110 images\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Add color channel\nX_train = X_train[..., np.newaxis]\nX_test = X_test[..., np.newaxis]\n\ninput_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_train))\n\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:08.395076Z","iopub.execute_input":"2024-12-14T18:42:08.395374Z","iopub.status.idle":"2024-12-14T18:42:09.442499Z","shell.execute_reply.started":"2024-12-14T18:42:08.395347Z","shell.execute_reply":"2024-12-14T18:42:09.441651Z"}},"outputs":[{"name":"stdout","text":"Input shape: (64, 128, 1)\nNumber of classes: 5\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def apply_augmentations(images, masks, aug_list):\n    \"\"\"\n    Applies a list of augmentations to images and masks, returning the augmented data.\n\n    Args:\n        images (np.ndarray): Array of input images.\n        masks (np.ndarray): Array of corresponding ground truth masks.\n        aug_list (list): List of augmentation functions to apply.\n\n    Returns:\n        dict: Dictionary containing augmented images under key \"images\" and augmented masks under key \"labels\".\n    \"\"\"\n    augmented_images = []\n    augmented_masks = []\n\n    for aug in aug_list:\n        for img, mask in zip(images, masks):\n            augmented = aug(image=img, mask=mask)\n            augmented_images.append(augmented['image'])\n            augmented_masks.append(augmented['mask'])\n\n    augmented_images = np.array(augmented_images)\n    augmented_masks = np.array(augmented_masks)\n\n    return {\"images\":augmented_images, \"labels\":augmented_masks}\n\n# Augmentations\nh_flip = A.HorizontalFlip(p=1.0)\nv_flip = A.VerticalFlip(p=1.0)\nrotation = A.Affine(rotate=180,p=1)\naugmentations = [h_flip, v_flip, rotation]\naug_dataset = apply_augmentations(X_train, y_train, augmentations)\nX_train, y_train = aug_dataset['images'], aug_dataset['labels']\n\nprint(f\"Training X shape: {X_train.shape}\")\nprint(f\"Training y shape: {y_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:09.443670Z","iopub.execute_input":"2024-12-14T18:42:09.444030Z","iopub.status.idle":"2024-12-14T18:42:11.658383Z","shell.execute_reply.started":"2024-12-14T18:42:09.443991Z","shell.execute_reply":"2024-12-14T18:42:11.657515Z"}},"outputs":[{"name":"stdout","text":"Training X shape: (7515, 64, 128, 1)\nTraining y shape: (7515, 64, 128)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Splitting in train-validation sets\ntrain_img, val_img, train_lbl, val_lbl = train_test_split(\n    X_train, y_train, test_size=0.1, random_state=seed\n)\nprint(\"Data splitted!\")\n\ntrain_lbl_cat = tf.one_hot(train_lbl, depth=num_classes)\nval_lbl_cat = tf.one_hot(val_lbl, depth=num_classes)\n\nprint(f\"\\nNumber of images:\")\nprint(f\"Train: {len(train_img)}\")\nprint(f\"Validation: {len(val_img)}\")\nprint(f\"\\nLabels shape:\")\nprint(f\"Train: {train_lbl_cat.shape}\")\nprint(f\"Validation: {val_lbl_cat.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:11.659500Z","iopub.execute_input":"2024-12-14T18:42:11.659772Z","iopub.status.idle":"2024-12-14T18:42:13.085321Z","shell.execute_reply.started":"2024-12-14T18:42:11.659746Z","shell.execute_reply":"2024-12-14T18:42:13.084492Z"}},"outputs":[{"name":"stdout","text":"Data splitted!\n\nNumber of images:\nTrain: 6763\nValidation: 752\n\nLabels shape:\nTrain: (6763, 64, 128, 5)\nValidation: (752, 64, 128, 5)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## üõ†Ô∏è Model Ensemble","metadata":{}},{"cell_type":"code","source":"@ks.register_keras_serializable()\nclass AdaptiveFusion(tf.keras.layers.Layer):\n    def __init__(self, num_inputs, **kwargs):\n        super(AdaptiveFusion, self).__init__(**kwargs)\n        self.num_inputs = num_inputs\n        self.gates = []\n\n    def build(self, input_shape):\n        # Creazione dei gate trainabili\n        self.gates = [\n            self.add_weight(\n                shape=(1,), \n                initializer=\"ones\", \n                trainable=True, \n                name=f\"gate_{i}\"\n            )\n            for i in range(self.num_inputs)\n        ]\n    \n    def call(self, inputs):\n        # Verifica che il numero di ingressi corrisponda al numero di gate\n        if len(inputs) != self.num_inputs:\n            raise ValueError(f\"Expected {self.num_inputs} inputs, but got {len(inputs)}.\")\n\n        # Calcolo della somma pesata\n        weighted_inputs = [gate * inp for gate, inp in zip(self.gates, inputs)]\n        output = tf.add_n(weighted_inputs)  # Somma i tensori ponderati\n        return output\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"num_inputs\": self.num_inputs})\n        return config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:13.086329Z","iopub.execute_input":"2024-12-14T18:42:13.086608Z","iopub.status.idle":"2024-12-14T18:42:13.093363Z","shell.execute_reply.started":"2024-12-14T18:42:13.086577Z","shell.execute_reply":"2024-12-14T18:42:13.092501Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"@ks.register_keras_serializable()\nclass EnsembleModel(tfk.Model):\n    \"\"\"\n    Custom ensemble model that combines predictions from multiple models using weighted averaging.\n\n    Args:\n        models (list): List of pre-trained models to include in the ensemble.\n        weights (list or np.array): Weights for combining the predictions of each model.\n    \"\"\"\n    def __init__(self, models, weights):\n        super(EnsembleModel, self).__init__()\n        self.models = models  # List of models\n        self.ensemble_weights = tf.constant(weights, dtype=tf.float32)  # Ensemble weights\n\n    def call(self, inputs):\n        # Collect predictions from each model\n        predictions = [self.models[0](inputs),self.models[1](inputs),self.models[2](inputs/255),self.models[3](inputs/255)]\n        predictions = tf.stack(predictions, axis=0)  # Stack along a new dimension\n\n        # Compute weighted predictions\n        weighted_predictions = tf.tensordot(predictions, self.ensemble_weights, axes=((0), (0)))\n        return tf.argmax(weighted_predictions, axis=-1) # The argmax is kept inside the class code, because we don't need this model for training only inference\n\n    def get_config(self):\n        # Save model configurations and weights for reloading\n        return {\n            \"models\": [model.to_json() for model in self.models],  # Save each model structure as JSON\n            \"weights\": self.ensemble_weights.numpy().tolist(),  # Convert tensor to Python list for serialization\n        }\n\n    @classmethod\n    def from_config(cls, config):\n        # Recreate models from JSON and reload weights\n        models = [tfk.models.model_from_json(model_json) for model_json in config[\"models\"]]\n        weights = config[\"weights\"]\n        return cls(models=models, weights=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:13.094421Z","iopub.execute_input":"2024-12-14T18:42:13.094732Z","iopub.status.idle":"2024-12-14T18:42:13.109724Z","shell.execute_reply.started":"2024-12-14T18:42:13.094697Z","shell.execute_reply":"2024-12-14T18:42:13.108722Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Set compile=False as we are not loading it for training, only for prediction.\nmodel1 = load_model('/kaggle/input/model1.keras', compile=False)\nmodel2 = load_model('/kaggle/input/model2.keras', compile=False)\nmodel3 = load_model('/kaggle/input/adaptive_fusion.keras', compile=False)\nmodel4 = load_model('/kaggle/input/adaptive fusion.keras', compile=False)\n\nmodels = [model1, model2, model3, model4]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:13.110677Z","iopub.execute_input":"2024-12-14T18:42:13.110961Z","iopub.status.idle":"2024-12-14T18:42:51.293527Z","shell.execute_reply.started":"2024-12-14T18:42:13.110938Z","shell.execute_reply":"2024-12-14T18:42:51.292572Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def calculate_classwise_miou(y_true, y_pred, num_classes):\n    \"\"\"\n    Calculate the mean Intersection over Union (mIoU) for each class.\n\n    Args:\n        y_true (np.array): Ground truth labels (e.g., shape: (batch, height, width)).\n        y_pred (np.array): Predicted labels (e.g., shape: (batch, height, width)).\n        num_classes (int): Total number of classes.\n\n    Returns:\n        dict: Dictionary of IoU values for each class.\n    \"\"\"\n    # Flatten the arrays\n    y_true_flat = y_true.flatten()\n    y_pred_flat = y_pred.flatten()\n\n    # Initialize the MeanIoU object\n    miou_metric = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0,)\n    miou_metric.update_state(y_true_flat, y_pred_flat)\n\n    # Extract IoU per class\n    total_conf_matrix = miou_metric.total_cm.numpy()  # Get the confusion matrix\n    ious = []\n    for i in range(num_classes):\n        TP = total_conf_matrix[i, i]  # True positives for class i\n        FP = total_conf_matrix[:, i].sum() - TP  # False positives for class i\n        FN = total_conf_matrix[i, :].sum() - TP  # False negatives for class i\n        denominator = TP + FP + FN\n        if denominator == 0:\n            iou = np.nan  # Handle classes not present in predictions or labels\n        else:\n            iou = TP / denominator\n        ious.append(iou)\n\n    # Create a dictionary for class-wise IoU\n    miou_per_class = {f\"Class {i}\": iou for i, iou in enumerate(ious)}\n    return miou_per_class\n\nval_lbl_pred1 = model1.predict(val_img)\nval_lbl_pred2 = model2.predict(val_img)\nval_lbl_pred3 = model3.predict(val_img/255)\nval_lbl_pred4 = model4.predict(val_img/255)\n\ny_pred_argmax1 = np.argmax(val_lbl_pred1, axis=-1)  # Convert one-hot predictions to class indices\ny_pred_argmax2 = np.argmax(val_lbl_pred2, axis=-1)  # Convert one-hot predictions to class indices\ny_pred_argmax3 = np.argmax(val_lbl_pred3, axis=-1)  # Convert one-hot predictions to class indices\ny_pred_argmax4 = np.argmax(val_lbl_pred4, axis=-1)  # Convert one-hot predictions to class indices\nval_lbl_argmax = np.argmax(val_lbl_cat, axis=-1)  # Convert one-hot labels to class indices\n\nmiou_per_class1 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax1, num_classes)\nmiou_per_class2 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax2, num_classes)\nmiou_per_class3 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax3, num_classes)\nmiou_per_class4 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax4, num_classes)\n\n# Print the IoU scores for each class\nprint(\"Class-wise IoU scores for model1:\")\nfor cls, score in miou_per_class1.items():\n    print(f\"{cls}: {score:.4f}\")\n\n# Print the IoU scores for each class\nprint(\"Class-wise IoU scores for model2:\")\nfor cls, score in miou_per_class2.items():\n    print(f\"{cls}: {score:.4f}\")\n\n# Print the IoU scores for each class\nprint(\"Class-wise IoU scores for model3:\")\nfor cls, score in miou_per_class3.items():\n    print(f\"{cls}: {score:.4f}\")\n\nprint(\"Class-wise IoU scores for model4:\")\nfor cls, score in miou_per_class4.items():\n    print(f\"{cls}: {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:42:51.296072Z","iopub.execute_input":"2024-12-14T18:42:51.296424Z","iopub.status.idle":"2024-12-14T18:43:43.009906Z","shell.execute_reply.started":"2024-12-14T18:42:51.296381Z","shell.execute_reply":"2024-12-14T18:43:43.008996Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734201772.876613      92 service.cc:145] XLA service 0x799afc004d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734201772.876671      92 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 8/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 17ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1734201778.082046      92 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 278ms/step\nClass-wise IoU scores for model1:\nClass 0: nan\nClass 1: 0.8558\nClass 2: 0.8084\nClass 3: 0.8655\nClass 4: 0.3231\nClass-wise IoU scores for model2:\nClass 0: nan\nClass 1: 0.8864\nClass 2: 0.8268\nClass 3: 0.8921\nClass 4: 0.0000\nClass-wise IoU scores for model3:\nClass 0: nan\nClass 1: 0.8659\nClass 2: 0.8166\nClass 3: 0.8958\nClass 4: 0.3206\nClass-wise IoU scores for model4:\nClass 0: nan\nClass 1: 0.8638\nClass 2: 0.8289\nClass 3: 0.8885\nClass 4: 0.3414\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Best ensemble model search\nbest = dict({'wts': [0.0, 0.0, 0.0, 0.0], 'IOU': 0.0, 'model': None}, index=[0])\nfor w1 in range(1,10):\n    wts = [w1/10.,0.1,0.1,0.1]\n    ensemble_model = EnsembleModel(models, wts)\n    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n    wted_ensemble_pred = ensemble_model.predict(val_img)\n    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n    print(\"Now predicting for weights :\", w1/10., 0.1, 0.1, 0.1, \" : IOU = \", IOU_wted.result().numpy())\n    if IOU_wted.result().numpy() > best.get('IOU'):\n        best = dict({'wts' : [wts[0], wts[1], wts[2], wts[3]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\nfor w2 in range(1,10):\n    wts = [0.1,w2/10.,0.1,0.1]\n    ensemble_model = EnsembleModel(models, wts)\n    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n    wted_ensemble_pred = ensemble_model.predict(val_img)\n    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n    print(\"Now predicting for weights :\", 0.1, w2/10., 0.1, 0.1, \" : IOU = \", IOU_wted.result().numpy())\n    if IOU_wted.result().numpy() > best.get('IOU'):\n        best = dict({'wts' : [wts[0], wts[1], wts[2], wts[3]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\nfor w3 in range(1,10):\n    wts = [0.1,0.1,w3/10.,0.1]\n    ensemble_model = EnsembleModel(models, wts)\n    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n    wted_ensemble_pred = ensemble_model.predict(val_img)\n    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n    print(\"Now predicting for weights :\", 0.1, 0.1, w3/10., 0.1, \" : IOU = \", IOU_wted.result().numpy())\n    if IOU_wted.result().numpy() > best.get('IOU'):\n        best = dict({'wts' : [wts[0], wts[1], wts[2], wts[3]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\nfor w4 in range(1,10):\n    wts = [0.1,0.1,0.1,w4/10.]\n    ensemble_model = EnsembleModel(models, wts)\n    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n    wted_ensemble_pred = ensemble_model.predict(val_img)\n    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n    print(\"Now predicting for weights :\", 0.1, 0.1, 0.1, w4/10., \" : IOU = \", IOU_wted.result().numpy())\n    if IOU_wted.result().numpy() > best.get('IOU'):\n        best = dict({'wts' : [wts[0], wts[1], wts[2], wts[3]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\n\nprint(\"Best weights found: \", best.get('wts'), \" : IOU = \", best.get('IOU'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:43:43.011292Z","iopub.execute_input":"2024-12-14T18:43:43.011578Z","iopub.status.idle":"2024-12-14T18:58:37.699046Z","shell.execute_reply.started":"2024-12-14T18:43:43.011552Z","shell.execute_reply":"2024-12-14T18:58:37.698214Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 619ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.1  : IOU =  0.73454505\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 598ms/step\nNow predicting for weights : 0.2 0.1 0.1 0.1  : IOU =  0.74893737\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 596ms/step\nNow predicting for weights : 0.3 0.1 0.1 0.1  : IOU =  0.73318624\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 594ms/step\nNow predicting for weights : 0.4 0.1 0.1 0.1  : IOU =  0.72375596\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 594ms/step\nNow predicting for weights : 0.5 0.1 0.1 0.1  : IOU =  0.7210529\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 601ms/step\nNow predicting for weights : 0.6 0.1 0.1 0.1  : IOU =  0.7195356\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 675ms/step\nNow predicting for weights : 0.7 0.1 0.1 0.1  : IOU =  0.7185537\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 592ms/step\nNow predicting for weights : 0.8 0.1 0.1 0.1  : IOU =  0.7178761\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 683ms/step\nNow predicting for weights : 0.9 0.1 0.1 0.1  : IOU =  0.71736366\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 597ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.1  : IOU =  0.73454505\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 681ms/step\nNow predicting for weights : 0.1 0.2 0.1 0.1  : IOU =  0.73030376\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 593ms/step\nNow predicting for weights : 0.1 0.3 0.1 0.1  : IOU =  0.6852016\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 687ms/step\nNow predicting for weights : 0.1 0.4 0.1 0.1  : IOU =  0.66464347\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 599ms/step\nNow predicting for weights : 0.1 0.5 0.1 0.1  : IOU =  0.66034925\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 695ms/step\nNow predicting for weights : 0.1 0.6 0.1 0.1  : IOU =  0.6585809\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 597ms/step\nNow predicting for weights : 0.1 0.7 0.1 0.1  : IOU =  0.65742517\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 697ms/step\nNow predicting for weights : 0.1 0.8 0.1 0.1  : IOU =  0.6565879\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 600ms/step\nNow predicting for weights : 0.1 0.9 0.1 0.1  : IOU =  0.65598625\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 711ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.1  : IOU =  0.73454505\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 608ms/step\nNow predicting for weights : 0.1 0.1 0.2 0.1  : IOU =  0.72348154\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 707ms/step\nNow predicting for weights : 0.1 0.1 0.3 0.1  : IOU =  0.7185478\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 598ms/step\nNow predicting for weights : 0.1 0.1 0.4 0.1  : IOU =  0.7095005\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 637ms/step\nNow predicting for weights : 0.1 0.1 0.5 0.1  : IOU =  0.708002\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 595ms/step\nNow predicting for weights : 0.1 0.1 0.6 0.1  : IOU =  0.70724124\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 627ms/step\nNow predicting for weights : 0.1 0.1 0.7 0.1  : IOU =  0.70683336\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 595ms/step\nNow predicting for weights : 0.1 0.1 0.8 0.1  : IOU =  0.7066737\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 615ms/step\nNow predicting for weights : 0.1 0.1 0.9 0.1  : IOU =  0.7065918\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 704ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.1  : IOU =  0.73454505\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 595ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.2  : IOU =  0.732917\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 722ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.3  : IOU =  0.7250391\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 598ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.4  : IOU =  0.7175992\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 722ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.5  : IOU =  0.71800774\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 602ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.6  : IOU =  0.7175227\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 720ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.7  : IOU =  0.7171252\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 603ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.8  : IOU =  0.71686804\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 714ms/step\nNow predicting for weights : 0.1 0.1 0.1 0.9  : IOU =  0.7172671\nBest weights found:  [0.2, 0.1, 0.1, 0.1]  : IOU =  0.74893737\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"pred1 = model1.predict(val_img)\npred2 = model2.predict(val_img)\npred3 = model3.predict(val_img/255)\npred4 = model4.predict(val_img/255)\n\ny_pred1_argmax=np.argmax(pred1, axis=3)\ny_pred2_argmax=np.argmax(pred2, axis=3)\ny_pred3_argmax=np.argmax(pred3, axis=3)\ny_pred4_argmax=np.argmax(pred4, axis=3)\n\nensemble_input = tfk.Input(shape=input_shape)\nensemble_model = best.get('model')\ndel best\nensemble_predictions = ensemble_model.predict(val_img)\n\nIOU1 = MeanIoU(num_classes=num_classes, ignore_class=0)  \nIOU2 = MeanIoU(num_classes=num_classes, ignore_class=0) \nIOU3 = MeanIoU(num_classes=num_classes, ignore_class=0)   \nIOU4 = MeanIoU(num_classes=num_classes, ignore_class=0)   \nIOU_weighted = MeanIoU(num_classes=num_classes, ignore_class=0)  \n\nIOU1.update_state(val_lbl, y_pred1_argmax)\nIOU2.update_state(val_lbl, y_pred2_argmax)\nIOU3.update_state(val_lbl, y_pred3_argmax)\nIOU4.update_state(val_lbl, y_pred4_argmax)\nIOU_weighted.update_state(val_lbl, ensemble_predictions)\n\nprint('IOU Score for model1 = ', IOU1.result().numpy())\nprint('IOU Score for model2 = ', IOU2.result().numpy())\nprint('IOU Score for model3 = ', IOU3.result().numpy())\nprint('IOU Score for model4 = ', IOU4.result().numpy())\nprint('IOU Score for weighted average ensemble = ', IOU_weighted.result().numpy())\n\ntimestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\nmodel_filename = f\"model_{timestep_str}.keras\"\nensemble_model.save(model_filename)\n\nprint(f\"Model saved to {model_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:58:37.700224Z","iopub.execute_input":"2024-12-14T18:58:37.700504Z","iopub.status.idle":"2024-12-14T18:58:50.627169Z","shell.execute_reply.started":"2024-12-14T18:58:37.700477Z","shell.execute_reply":"2024-12-14T18:58:50.626268Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step\nIOU Score for model1 =  0.71318656\nIOU Score for model2 =  0.65132415\nIOU Score for model3 =  0.72474545\nIOU Score for model4 =  0.7306192\nIOU Score for weighted average ensemble =  0.74893737\nModel saved to model_241214_185848.keras\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## üìä Prepare Your Submission\n\nIn our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n\n","metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":"# If model_filename is not defined, load the most recent model from Google Drive\nif \"model_filename\" not in globals() or model_filename is None:\n    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n    if files:\n        model_filename = files[0]\n    else:\n        raise FileNotFoundError(\"No model files found in the current directory.\")","metadata":{"id":"BU00iEFcYi_X","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:58:50.628189Z","iopub.execute_input":"2024-12-14T18:58:50.628451Z","iopub.status.idle":"2024-12-14T18:58:50.633858Z","shell.execute_reply.started":"2024-12-14T18:58:50.628426Z","shell.execute_reply":"2024-12-14T18:58:50.632904Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"preds = ensemble_model.predict(X_test)\nprint(f\"Predictions shape: {preds.shape}\")","metadata":{"id":"z287uIQ_VGoK","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:58:50.634858Z","iopub.execute_input":"2024-12-14T18:58:50.635107Z","iopub.status.idle":"2024-12-14T19:00:16.171543Z","shell.execute_reply.started":"2024-12-14T18:58:50.635061Z","shell.execute_reply":"2024-12-14T19:00:16.170601Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m314/314\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 234ms/step\nPredictions shape: (10022, 64, 128)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def y_to_df(y) -> pd.DataFrame:\n    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n    n_samples = len(y)\n    y_flat = y.reshape(n_samples, -1)\n    df = pd.DataFrame(y_flat)\n    df[\"id\"] = np.arange(n_samples)\n    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n    return df[cols]","metadata":{"id":"SPjMEKqZW5jX","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:00:16.172609Z","iopub.execute_input":"2024-12-14T19:00:16.172884Z","iopub.status.idle":"2024-12-14T19:00:16.178093Z","shell.execute_reply.started":"2024-12-14T19:00:16.172860Z","shell.execute_reply":"2024-12-14T19:00:16.177123Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Create and download the csv submission file\ntimestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\nsubmission_filename = f\"submission_{timestep_str}.csv\"\nsubmission_df = y_to_df(preds)\nsubmission_df.to_csv(submission_filename, index=False)\n\n%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink(submission_filename)","metadata":{"id":"s18kX1uDconq","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:00:16.179241Z","iopub.execute_input":"2024-12-14T19:00:16.179598Z","iopub.status.idle":"2024-12-14T19:00:40.172721Z","shell.execute_reply.started":"2024-12-14T19:00:16.179563Z","shell.execute_reply":"2024-12-14T19:00:40.171832Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission_241214_185848.csv","text/html":"<a href='submission_241214_185848.csv' target='_blank'>submission_241214_185848.csv</a><br>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"#  \n<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/","metadata":{"id":"cQEgmFTPfz1n"}}]}