{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":10201347,"datasetId":6192936,"databundleVersionId":10492197}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Artificial Neural Networks and Deep Learning\n","\n","---\n","\n","## SiumGPT Homework 2 Final Notebook (Models Ensemble)"],"metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":["## ⚙️ Import Libraries"],"metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":["# Set seed for reproducibility\n","seed = 42\n","\n","# Import necessary libraries\n","import os\n","\n","# Set environment variables before importing modules\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","#os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n","\n","# Suppress warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","# Import necessary modules\n","import logging\n","import random\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","\n","# Set seeds for random number generators in NumPy and Python\n","np.random.seed(seed)\n","random.seed(seed)\n","\n","# Import TensorFlow and Keras\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","# Set seed for TensorFlow\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","\n","# Reduce TensorFlow verbosity\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","# Print TensorFlow version\n","print(tf.__version__)\n","\n","# Import other libraries\n","import albumentations as A\n","import os\n","import math\n","from PIL import Image\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import tensorflow.keras.backend as K\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import Counter\n","from keras.utils import to_categorical\n","from keras.saving import load_model\n","from keras.metrics import MeanIoU\n","from keras import saving as ks\n","\n","# Configure plot display settings\n","sns.set(font_scale=1.4)\n","sns.set_style('white')\n","plt.rc('font', size=14)\n","%matplotlib inline\n","\n","!pip install -U segmentation-models\n","import segmentation_models as sm\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"Keras version: {tfk.__version__}\")\n","print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"],"metadata":{"id":"CO6_Ft_8T56A","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:40.920529Z","iopub.execute_input":"2024-12-14T21:07:40.920887Z","iopub.status.idle":"2024-12-14T21:07:49.294491Z","shell.execute_reply.started":"2024-12-14T21:07:40.920857Z","shell.execute_reply":"2024-12-14T21:07:49.293384Z"},"outputId":"8575f36d-1848-44f2-fe34-aeb99fb4cd68"},"outputs":[{"name":"stdout","text":"2.16.1\nRequirement already satisfied: segmentation-models in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from segmentation-models) (1.0.8)\nRequirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models) (1.0.0)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models) (1.0.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet==1.0.0->segmentation-models) (0.23.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.26.4)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.11.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.14.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet==1.0.0->segmentation-models) (3.1.2)\nTensorFlow version: 2.16.1\nKeras version: 3.3.3\nGPU devices: 1\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["## ⏳ Load the Data"],"metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":["data = np.load(\"/kaggle/input/mars_for_students.npz\")\n","\n","training_set = data[\"training_set\"]\n","X_train = training_set[:, 0]\n","y_train = training_set[:, 1]\n","\n","X_test = data[\"test_set\"]\n","\n","# not used, just as a reference\n","labels = {\n","    0: \"Background\",\n","    1: \"Soil\",\n","    2: \"Bedrock\",\n","    3: \"Sand\",\n","    4: \"Big Rock\"\n","}\n","\n","print(f\"Training X shape: {X_train.shape}\")\n","print(f\"Training y shape: {y_train.shape}\")\n","print(f\"Test X shape: {X_test.shape}\")"],"metadata":{"id":"pLaoDaG1V1Yg","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:49.296361Z","iopub.execute_input":"2024-12-14T21:07:49.296691Z","iopub.status.idle":"2024-12-14T21:07:50.659822Z","shell.execute_reply.started":"2024-12-14T21:07:49.296661Z","shell.execute_reply":"2024-12-14T21:07:50.659109Z"},"outputId":"a39da7c5-02ed-4603-c247-bd1fe0bd44fb"},"outputs":[{"name":"stdout","text":"Training X shape: (2615, 64, 128)\nTraining y shape: (2615, 64, 128)\nTest X shape: (10022, 64, 128)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# Removing aliens\n","alien_label = y_train[1834, :]\n","#plt.imshow(alien_label, cmap='viridis')\n","\n","filter = [True] * X_train.shape[0]\n","removed = 0\n","for i, lab in enumerate(y_train):\n","    if np.array_equal(alien_label, lab):\n","        filter[i] = False\n","        removed += 1\n","\n","X_train = X_train[filter]\n","y_train = y_train[filter]\n","\n","print(f\"Training X shape: {X_train.shape}\")\n","print(f\"Training y shape: {y_train.shape}\")\n","print(f'Removed {removed} images')"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:50.661039Z","iopub.execute_input":"2024-12-14T21:07:50.661690Z","iopub.status.idle":"2024-12-14T21:07:50.841507Z","shell.execute_reply.started":"2024-12-14T21:07:50.661649Z","shell.execute_reply":"2024-12-14T21:07:50.840395Z"},"id":"8qqO_BY2Tzuj","outputId":"c857b747-55ea-4b5e-8fd5-73e71e550184"},"outputs":[{"name":"stdout","text":"Training X shape: (2505, 64, 128)\nTraining y shape: (2505, 64, 128)\nRemoved 110 images\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# Add color channel\n","X_train = X_train[..., np.newaxis]\n","X_test = X_test[..., np.newaxis]\n","\n","input_shape = X_train.shape[1:]\n","num_classes = len(np.unique(y_train))\n","\n","print(f\"Input shape: {input_shape}\")\n","print(f\"Number of classes: {num_classes}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:50.842676Z","iopub.execute_input":"2024-12-14T21:07:50.842998Z","iopub.status.idle":"2024-12-14T21:07:51.896493Z","shell.execute_reply.started":"2024-12-14T21:07:50.842968Z","shell.execute_reply":"2024-12-14T21:07:51.895587Z"},"id":"Iilumg8KTzuj","outputId":"9e1742c7-6148-4588-feab-baf81add5d69"},"outputs":[{"name":"stdout","text":"Input shape: (64, 128, 1)\nNumber of classes: 5\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["def apply_augmentations(images, masks, aug_list):\n","    \"\"\"\n","    Applies a list of augmentations to images and masks, returning the augmented data.\n","\n","    Args:\n","        images (np.ndarray): Array of input images.\n","        masks (np.ndarray): Array of corresponding ground truth masks.\n","        aug_list (list): List of augmentation functions to apply.\n","\n","    Returns:\n","        dict: Dictionary containing augmented images under key \"images\" and augmented masks under key \"labels\".\n","    \"\"\"\n","    augmented_images = []\n","    augmented_masks = []\n","\n","    for aug in aug_list:\n","        for img, mask in zip(images, masks):\n","            augmented = aug(image=img, mask=mask)\n","            augmented_images.append(augmented['image'])\n","            augmented_masks.append(augmented['mask'])\n","\n","    augmented_images = np.array(augmented_images)\n","    augmented_masks = np.array(augmented_masks)\n","\n","    return {\"images\":augmented_images, \"labels\":augmented_masks}\n","\n","# Augmentations\n","h_flip = A.HorizontalFlip(p=1.0)\n","v_flip = A.VerticalFlip(p=1.0)\n","rotation = A.Affine(rotate=180,p=1)\n","augmentations = [h_flip, v_flip, rotation]\n","aug_dataset = apply_augmentations(X_train, y_train, augmentations)\n","X_train, y_train = aug_dataset['images'], aug_dataset['labels']\n","\n","print(f\"Training X shape: {X_train.shape}\")\n","print(f\"Training y shape: {y_train.shape}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:51.898468Z","iopub.execute_input":"2024-12-14T21:07:51.898767Z","iopub.status.idle":"2024-12-14T21:07:56.407098Z","shell.execute_reply.started":"2024-12-14T21:07:51.898739Z","shell.execute_reply":"2024-12-14T21:07:56.406131Z"},"id":"qHTDcU3TTzuk","outputId":"cb15d410-b401-4318-ea7f-d77ffc71d086"},"outputs":[{"name":"stdout","text":"Training X shape: (7515, 64, 128, 1)\nTraining y shape: (7515, 64, 128)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# Splitting in train-validation sets\n","train_img, val_img, train_lbl, val_lbl = train_test_split(\n","    X_train, y_train, test_size=0.1, random_state=seed\n",")\n","print(\"Data splitted!\")\n","\n","train_lbl_cat = tf.one_hot(train_lbl, depth=num_classes)\n","val_lbl_cat = tf.one_hot(val_lbl, depth=num_classes)\n","\n","print(f\"\\nNumber of images:\")\n","print(f\"Train: {len(train_img)}\")\n","print(f\"Validation: {len(val_img)}\")\n","print(f\"\\nLabels shape:\")\n","print(f\"Train: {train_lbl_cat.shape}\")\n","print(f\"Validation: {val_lbl_cat.shape}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:56.407977Z","iopub.execute_input":"2024-12-14T21:07:56.408260Z","iopub.status.idle":"2024-12-14T21:07:57.425918Z","shell.execute_reply.started":"2024-12-14T21:07:56.408232Z","shell.execute_reply":"2024-12-14T21:07:57.424874Z"},"id":"tta2JQlRTzuk","outputId":"86d28311-e685-4f10-e4a0-f6539de7ea7c"},"outputs":[{"name":"stdout","text":"Data splitted!\n\nNumber of images:\nTrain: 6763\nValidation: 752\n\nLabels shape:\nTrain: (6763, 64, 128, 5)\nValidation: (752, 64, 128, 5)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["## 🛠️ Model Ensemble"],"metadata":{"id":"1fzM692GTzuk"}},{"cell_type":"code","source":["@ks.register_keras_serializable()\n","class EnsembleModel(tfk.Model):\n","    \"\"\"\n","    Custom ensemble model that combines predictions from multiple models using weighted averaging.\n","\n","    Args:\n","        models (list): List of pre-trained models to include in the ensemble.\n","        weights (list or np.array): Weights for combining the predictions of each model.\n","    \"\"\"\n","    def __init__(self, models, weights):\n","        super(EnsembleModel, self).__init__()\n","        self.models = models  # List of models\n","        self.ensemble_weights = tf.constant(weights, dtype=tf.float32)  # Ensemble weights\n","\n","    def call(self, inputs):\n","        # Collect predictions from each model\n","        predictions = [model(inputs) for model in self.models]\n","        predictions = tf.stack(predictions, axis=0)  # Stack along a new dimension\n","\n","        # Compute weighted predictions\n","        weighted_predictions = tf.tensordot(predictions, self.ensemble_weights, axes=((0), (0)))\n","        return tf.argmax(weighted_predictions, axis=-1) # The argmax is kept inside the class code, because we don't need this model for training only inference\n","\n","    def get_config(self):\n","        # Save model configurations and weights for reloading\n","        return {\n","            \"models\": [model.to_json() for model in self.models],  # Save each model structure as JSON\n","            \"weights\": self.ensemble_weights.numpy().tolist(),  # Convert tensor to Python list for serialization\n","        }\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        # Recreate models from JSON and reload weights\n","        models = [tfk.models.model_from_json(model_json) for model_json in config[\"models\"]]\n","        weights = config[\"weights\"]\n","        return cls(models=models, weights=weights)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:57.427233Z","iopub.execute_input":"2024-12-14T21:07:57.427635Z","iopub.status.idle":"2024-12-14T21:07:57.436000Z","shell.execute_reply.started":"2024-12-14T21:07:57.427592Z","shell.execute_reply":"2024-12-14T21:07:57.435074Z"},"id":"mifKTmSoTzul"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["#Set compile=False as we are not loading it for training, only for prediction.\n","model1 = load_model('/kaggle/input/model1.keras', compile=False)\n","model2 = load_model('/kaggle/input/model2.keras', compile=False)\n","\n","models = [model1, model2]"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:07:57.437062Z","iopub.execute_input":"2024-12-14T21:07:57.437317Z","iopub.status.idle":"2024-12-14T21:08:18.108313Z","shell.execute_reply.started":"2024-12-14T21:07:57.437293Z","shell.execute_reply":"2024-12-14T21:08:18.107475Z"},"id":"PQamMvnsTzul"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def calculate_classwise_miou(y_true, y_pred, num_classes):\n","    \"\"\"\n","    Calculate the mean Intersection over Union (mIoU) for each class.\n","\n","    Args:\n","        y_true (np.array): Ground truth labels (e.g., shape: (batch, height, width)).\n","        y_pred (np.array): Predicted labels (e.g., shape: (batch, height, width)).\n","        num_classes (int): Total number of classes.\n","\n","    Returns:\n","        dict: Dictionary of IoU values for each class.\n","    \"\"\"\n","    # Flatten the arrays\n","    y_true_flat = y_true.flatten()\n","    y_pred_flat = y_pred.flatten()\n","\n","    # Initialize the MeanIoU object\n","    miou_metric = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0,)\n","    miou_metric.update_state(y_true_flat, y_pred_flat)\n","\n","    # Extract IoU per class\n","    total_conf_matrix = miou_metric.total_cm.numpy()  # Get the confusion matrix\n","    ious = []\n","    for i in range(num_classes):\n","        TP = total_conf_matrix[i, i]  # True positives for class i\n","        FP = total_conf_matrix[:, i].sum() - TP  # False positives for class i\n","        FN = total_conf_matrix[i, :].sum() - TP  # False negatives for class i\n","        denominator = TP + FP + FN\n","        if denominator == 0:\n","            iou = np.nan  # Handle classes not present in predictions or labels\n","        else:\n","            iou = TP / denominator\n","        ious.append(iou)\n","\n","    # Create a dictionary for class-wise IoU\n","    miou_per_class = {f\"Class {i}\": iou for i, iou in enumerate(ious)}\n","    return miou_per_class\n","\n","val_lbl_pred1 = model1.predict(val_img)\n","val_lbl_pred2 = model2.predict(val_img)\n","\n","y_pred_argmax1 = np.argmax(val_lbl_pred1, axis=-1)  # Convert one-hot predictions to class indices\n","y_pred_argmax2 = np.argmax(val_lbl_pred2, axis=-1)  # Convert one-hot predictions to class indices\n","val_lbl_argmax = np.argmax(val_lbl_cat, axis=-1)  # Convert one-hot labels to class indices\n","\n","miou_per_class1 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax1, num_classes)\n","miou_per_class2 = calculate_classwise_miou(val_lbl_argmax, y_pred_argmax2, num_classes)\n","\n","# Print the IoU scores for each class\n","print(\"Class-wise IoU scores for model1:\")\n","for cls, score in miou_per_class1.items():\n","    print(f\"{cls}: {score:.4f}\")\n","\n","# Print the IoU scores for each class\n","print(\"Class-wise IoU scores for model2:\")\n","for cls, score in miou_per_class2.items():\n","    print(f\"{cls}: {score:.4f}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:08:18.109325Z","iopub.execute_input":"2024-12-14T21:08:18.109594Z","iopub.status.idle":"2024-12-14T21:08:37.515777Z","shell.execute_reply.started":"2024-12-14T21:08:18.109569Z","shell.execute_reply":"2024-12-14T21:08:37.514838Z"},"id":"RCf0Id8qTzul","outputId":"95a164e7-83f5-43e5-e14b-a7d60b62cdfd"},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734210499.807522     138 service.cc:145] XLA service 0x7c08f0003040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734210499.807607     138 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 8/24\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1734210505.010945     138 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step\nClass-wise IoU scores for model1:\nClass 0: nan\nClass 1: 0.8558\nClass 2: 0.8084\nClass 3: 0.8655\nClass 4: 0.3231\nClass-wise IoU scores for model2:\nClass 0: nan\nClass 1: 0.8864\nClass 2: 0.8268\nClass 3: 0.8921\nClass 4: 0.0000\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["# Best ensemble model search\n","best = dict({'wts': [0.0, 0.0], 'IOU': 0.0, 'model': None}, index=[0])\n","for w1 in range(1,10):\n","    wts = [w1/10.,0.1]\n","    ensemble_model = EnsembleModel(models, wts)\n","    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n","    wted_ensemble_pred = ensemble_model.predict(val_img)\n","    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n","    print(\"Now predicting for weights :\", w1/10., 0.1, \" : IOU = \", IOU_wted.result().numpy())\n","    if IOU_wted.result().numpy() > best.get('IOU'):\n","        best = dict({'wts' : [wts[0], wts[1]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\n","for w2 in range(1,10):\n","    wts = [0.1,w2/10.]\n","    ensemble_model = EnsembleModel(models, wts)\n","    IOU_wted = MeanIoU(num_classes=num_classes, ignore_class=0)\n","    wted_ensemble_pred = ensemble_model.predict(val_img)\n","    IOU_wted.update_state(val_lbl, wted_ensemble_pred)\n","    print(\"Now predicting for weights :\", 0.1, w2/10., \" : IOU = \", IOU_wted.result().numpy())\n","    if IOU_wted.result().numpy() > best.get('IOU'):\n","        best = dict({'wts' : [wts[0], wts[1]],'IOU': IOU_wted.result().numpy(), 'model': ensemble_model}, index=[0])\n","\n","print(\"Best weights found: \", best.get('wts'), \" : IOU = \", best.get('IOU'))"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:08:37.516992Z","iopub.execute_input":"2024-12-14T21:08:37.517395Z","iopub.status.idle":"2024-12-14T21:12:25.818288Z","shell.execute_reply.started":"2024-12-14T21:08:37.517351Z","shell.execute_reply":"2024-12-14T21:12:25.817366Z"},"id":"7FEcYa-8Tzul","outputId":"22c8636e-9c68-4235-8e15-ae069a04f4eb"},"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step\nNow predicting for weights : 0.1 0.1  : IOU =  0.73554194\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step\nNow predicting for weights : 0.2 0.1  : IOU =  0.7204041\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step\nNow predicting for weights : 0.3 0.1  : IOU =  0.717947\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 284ms/step\nNow predicting for weights : 0.4 0.1  : IOU =  0.7168317\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 273ms/step\nNow predicting for weights : 0.5 0.1  : IOU =  0.7161571\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step\nNow predicting for weights : 0.6 0.1  : IOU =  0.71564746\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step\nNow predicting for weights : 0.7 0.1  : IOU =  0.7153106\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 273ms/step\nNow predicting for weights : 0.8 0.1  : IOU =  0.7150263\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 331ms/step\nNow predicting for weights : 0.9 0.1  : IOU =  0.7148258\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 279ms/step\nNow predicting for weights : 0.1 0.1  : IOU =  0.73554194\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step\nNow predicting for weights : 0.1 0.2  : IOU =  0.65897703\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 342ms/step\nNow predicting for weights : 0.1 0.3  : IOU =  0.65514606\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 282ms/step\nNow predicting for weights : 0.1 0.4  : IOU =  0.6542245\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step\nNow predicting for weights : 0.1 0.5  : IOU =  0.65373856\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 349ms/step\nNow predicting for weights : 0.1 0.6  : IOU =  0.6534081\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 283ms/step\nNow predicting for weights : 0.1 0.7  : IOU =  0.65316236\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step\nNow predicting for weights : 0.1 0.8  : IOU =  0.65296865\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 353ms/step\nNow predicting for weights : 0.1 0.9  : IOU =  0.65282375\nBest weights found:  [0.1, 0.1]  : IOU =  0.73554194\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["pred1 = model1.predict(val_img)\n","pred2 = model2.predict(val_img)\n","\n","y_pred1_argmax=np.argmax(pred1, axis=3)\n","y_pred2_argmax=np.argmax(pred2, axis=3)\n","\n","ensemble_input = tfk.Input(shape=input_shape)\n","ensemble_model = best.get('model')\n","del best\n","ensemble_predictions = ensemble_model.predict(val_img)\n","\n","IOU1 = MeanIoU(num_classes=num_classes, ignore_class=0)\n","IOU2 = MeanIoU(num_classes=num_classes, ignore_class=0)\n","IOU_weighted = MeanIoU(num_classes=num_classes, ignore_class=0)\n","\n","IOU1.update_state(val_lbl, y_pred1_argmax)\n","IOU2.update_state(val_lbl, y_pred2_argmax)\n","IOU_weighted.update_state(val_lbl, ensemble_predictions)\n","\n","print('IOU Score for model1 = ', IOU1.result().numpy())\n","print('IOU Score for model2 = ', IOU2.result().numpy())\n","print('IOU Score for weighted average ensemble = ', IOU_weighted.result().numpy())\n","\n","miou_per_class = calculate_classwise_miou(val_lbl_argmax, ensemble_predictions, num_classes)\n","\n","# Print the IoU scores for each class\n","print(\"Class-wise IoU scores:\")\n","for cls, score in miou_per_class.items():\n","    print(f\"{cls}: {score:.4f}\")\n","\n","timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n","model_filename = f\"model_{timestep_str}.keras\"\n","ensemble_model.save(model_filename)\n","\n","print(f\"Model saved to {model_filename}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:12:25.819773Z","iopub.execute_input":"2024-12-14T21:12:25.820150Z","iopub.status.idle":"2024-12-14T21:12:29.971258Z","shell.execute_reply.started":"2024-12-14T21:12:25.820112Z","shell.execute_reply":"2024-12-14T21:12:29.970369Z"},"id":"PHD5FfdwTzum","outputId":"d6b4c1a4-8b28-4ecb-c940-c3544adedcff"},"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\nIOU Score for model1 =  0.71318656\nIOU Score for model2 =  0.65132415\nIOU Score for weighted average ensemble =  0.73554194\nClass-wise IoU scores:\nClass 0: nan\nClass 1: 0.8829\nClass 2: 0.8401\nClass 3: 0.8928\nClass 4: 0.3264\nModel saved to model_241214_211228.keras\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["## 📊 Prepare Your Submission\n","\n","In our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n","\n"],"metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":["# If model_filename is not defined, load the most recent model from Google Drive\n","if \"model_filename\" not in globals() or model_filename is None:\n","    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n","    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n","    if files:\n","        model_filename = files[0]\n","    else:\n","        raise FileNotFoundError(\"No model files found in the current directory.\")"],"metadata":{"id":"BU00iEFcYi_X","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:12:29.972199Z","iopub.execute_input":"2024-12-14T21:12:29.972469Z","iopub.status.idle":"2024-12-14T21:12:29.977691Z","shell.execute_reply.started":"2024-12-14T21:12:29.972427Z","shell.execute_reply":"2024-12-14T21:12:29.976865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["preds = ensemble_model.predict(X_test)\n","print(f\"Predictions shape: {preds.shape}\")"],"metadata":{"id":"z287uIQ_VGoK","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:12:29.978684Z","iopub.execute_input":"2024-12-14T21:12:29.978930Z","iopub.status.idle":"2024-12-14T21:12:56.485151Z","shell.execute_reply.started":"2024-12-14T21:12:29.978907Z","shell.execute_reply":"2024-12-14T21:12:56.484216Z"},"outputId":"7120fd32-c1ea-457f-fea4-5039c58f751c"},"outputs":[{"name":"stdout","text":"\u001b[1m314/314\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 61ms/step\nPredictions shape: (10022, 64, 128)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["def y_to_df(y) -> pd.DataFrame:\n","    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n","    n_samples = len(y)\n","    y_flat = y.reshape(n_samples, -1)\n","    df = pd.DataFrame(y_flat)\n","    df[\"id\"] = np.arange(n_samples)\n","    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n","    return df[cols]"],"metadata":{"id":"SPjMEKqZW5jX","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:12:56.487755Z","iopub.execute_input":"2024-12-14T21:12:56.488040Z","iopub.status.idle":"2024-12-14T21:12:56.492843Z","shell.execute_reply.started":"2024-12-14T21:12:56.488013Z","shell.execute_reply":"2024-12-14T21:12:56.492003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Create and download the csv submission file\n","timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n","submission_filename = f\"submission_{timestep_str}.csv\"\n","submission_df = y_to_df(preds)\n","submission_df.to_csv(submission_filename, index=False)\n","\n","%cd /kaggle/working\n","from IPython.display import FileLink\n","FileLink(submission_filename)"],"metadata":{"id":"s18kX1uDconq","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:12:56.493840Z","iopub.execute_input":"2024-12-14T21:12:56.494057Z","iopub.status.idle":"2024-12-14T21:13:19.665640Z","shell.execute_reply.started":"2024-12-14T21:12:56.494036Z","shell.execute_reply":"2024-12-14T21:13:19.664807Z"},"outputId":"433f9c4e-8243-4772-b623-d5d9df9922a2"},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission_241214_211228.csv","text/html":"<a href='submission_241214_211228.csv' target='_blank'>submission_241214_211228.csv</a><br>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":["#  \n","<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/"],"metadata":{"id":"cQEgmFTPfz1n"}}]}